{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "602f905a",
   "metadata": {},
   "source": [
    "This assignemt uses the [_LED Display Domain Data Set_ from the _UCI Machine Learning Repository_](https://archive.ics.uci.edu/ml/datasets/LED+Display+Domain)\n",
    "\n",
    "Dataset description:\n",
    "> This simple domain contains 7 Boolean attributes and 10 concepts, the set of decimal digits. Recall that LED displays contain 7 light-emitting diodes -- hence the reason for 7 attributes. The problem would be easy if not for the introduction of noise. In this case, each attribute value has the 10% probability of having its value inverted. \n",
    "\n",
    "The authors provide two C programs for generating the actual data.\n",
    "I chose to use the _led-creator.c_ which accepts arguments _numtrain seed outputfile noise_\n",
    "where, as stated in the C code:\n",
    " - numtrain is the number of training instances requested\n",
    " - seed is an integer seed for the random number generator\n",
    " - outputfile: output file name for the generated instances\n",
    " - noise is the percent probability of noise per attribute (usually set to 10%...and reported by the program)\n",
    " \n",
    "I used arguments _4000 11 nums.csv 10_ and the program reported _Percent Noise: Requested 10, Actual 9.939285_\n",
    "</br></br>\n",
    "Code inspiration and sources: </br>\n",
    "Most code was taken from assignments or class materials </br>\n",
    "The Bayes implementation example was taken from the [_sklearn documentation_](https://scikit-learn.org/stable/modules/naive_bayes.html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349f7d4b",
   "metadata": {},
   "source": [
    "\n",
    "In the first cell all imports are declared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "88abdc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.naive_bayes import GaussianNB, CategoricalNB\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0a2cfa",
   "metadata": {},
   "source": [
    "The first thing to do is load the dataset. \n",
    "As the file doesn't have a row which contains column names, the names are passed as a parameter to the _read_csv_ function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8cbc8950",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>led_1</th>\n",
       "      <th>led_2</th>\n",
       "      <th>led_3</th>\n",
       "      <th>led_4</th>\n",
       "      <th>led_5</th>\n",
       "      <th>led_6</th>\n",
       "      <th>led_7</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   led_1  led_2  led_3  led_4  led_5  led_6  led_7  label\n",
       "0      0      0      1      0      1      1      0      1\n",
       "1      1      1      0      1      0      1      1      9\n",
       "2      0      0      1      0      0      0      0      1\n",
       "3      1      1      0      1      1      1      1      6\n",
       "4      1      1      1      0      1      0      1      0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('nums.csv', names=['led_1', 'led_2', 'led_3', 'led_4', 'led_5', 'led_6', 'led_7', 'label'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82834159",
   "metadata": {},
   "source": [
    "Let's see if the data was processed as numbers or needs casting or some other preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7189623",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "led_1    int64\n",
       "led_2    int64\n",
       "led_3    int64\n",
       "led_4    int64\n",
       "led_5    int64\n",
       "led_6    int64\n",
       "led_7    int64\n",
       "label    int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699ac626",
   "metadata": {},
   "source": [
    "Splitting the data into X, y, training and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a114c22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2800, 7) (1200, 7)\n"
     ]
    }
   ],
   "source": [
    "cols = df.columns\n",
    "cols = cols[cols != 'label']\n",
    "\n",
    "X = df[cols].values\n",
    "y = df['label'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "    test_size=0.30, shuffle=True, random_state=11)\n",
    "\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467d3230",
   "metadata": {},
   "source": [
    "As this is a classification problem, the first model I decided to try was k Nearest Neighbor with different k values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "989148a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(x1, x2):\n",
    "    return np.linalg.norm(x1-x2)\n",
    "\n",
    "class k_nearest_neighbor:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def fit(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "    def get_nearest(self, x, n):\n",
    "        distances = [distance(x, self.X[i]) \n",
    "                     for i in range(len(self.X))]\n",
    "        return np.array(distances).argsort()[:n]\n",
    "    def predict(self, x, n) :\n",
    "        votes = self.y[self.get_nearest(x, n)]\n",
    "        democracy = stats.mode(votes)\n",
    "        return democracy.mode[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81b2203c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_k_nearest_neighbors(k, X_train, y_train, X_test, y_test) :\n",
    "    knn = k_nearest_neighbor()\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred = np.array([knn.predict(X_test[i],k) for i in range(len(X_test))])\n",
    "    acc = np.sum(y_pred == y_test)/len(y_test)\n",
    "    # print(f'The accuracy is {acc:.3f}')\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c07ce8eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For k equals 1 the accuracy is 0.6900\n",
      "For k equals 2 the accuracy is 0.6900\n",
      "For k equals 3 the accuracy is 0.7283\n",
      "For k equals 4 the accuracy is 0.7142\n",
      "For k equals 5 the accuracy is 0.7225\n",
      "For k equals 6 the accuracy is 0.7250\n",
      "For k equals 7 the accuracy is 0.7183\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,8) :\n",
    "    acc = run_k_nearest_neighbors(i, X_train, y_train, X_test, y_test)\n",
    "    print(f'For k equals {i} the accuracy is {acc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1680b142",
   "metadata": {},
   "source": [
    "Normal knn took a long time to run, what if we tried Nearest Neigbor with exemplars, that should make computing faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95af9049",
   "metadata": {},
   "outputs": [],
   "source": [
    "class nearest_neighbor:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def fit(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "    def get_nearest(self, x):\n",
    "        distances = [distance(x, self.X[i]) \n",
    "                     for i in range(len(self.X))]\n",
    "        return np.argmin(distances)\n",
    "    def predict(self, x) :\n",
    "        return self.y[self.get_nearest(x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57cdad15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_nearest_neighbors(X_train, y_train, X_test, y_test) :\n",
    "    nn = nearest_neighbor()\n",
    "    nn.fit(X_train, y_train)\n",
    "    y_pred = np.array([nn.predict(X_test[i]) for i in range(len(X_test))])\n",
    "    acc = np.sum(y_pred == y_test)/len(y_test)\n",
    "    print(f'The accuracy is {acc:.3f}')\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "351c8be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_examplars(X_train, y_train) :\n",
    "    the_exemplars = []\n",
    "#     range(10)\n",
    "    for classs in set(y_train):\n",
    "        x_of_class = X_train[y_train==classs]\n",
    "        ptdsts = []\n",
    "        \n",
    "        for i in range(len(x_of_class)) :\n",
    "            alldst = [np.sqrt(np.sum((x_of_class[j]-x_of_class[i])*(x_of_class[j]-x_of_class[i]))) for j in range(len(x_of_class))]\n",
    "            ptdsts.append(sum(alldst))\n",
    "            \n",
    "        the_exemplars.append(x_of_class[np.argmin(ptdsts)])\n",
    "        \n",
    "        \n",
    "    return the_exemplars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b1bd4b33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is 0.733\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7333333333333333"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_exemplars = class_examplars(X_train, y_train)\n",
    "y_exemplars = [i for i in range(10)]\n",
    "\n",
    "run_nearest_neighbors(X_exemplars, y_exemplars, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6dd04b",
   "metadata": {},
   "source": [
    "Computing speed definitely increased, but accuracy remained about the same\n",
    "what about class means?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cb5b9556",
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_means(X_train, y_train) :\n",
    "    the_means = []\n",
    "#     range(10)\n",
    "    for classs in set(y_train):\n",
    "        x_of_class = X_train[y_train==classs ]\n",
    "        the_means.append(x_of_class.mean(axis=0))\n",
    "        \n",
    "    return the_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7ac56768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is 0.716\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7158333333333333"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_means = class_means(X_train, y_train)\n",
    "y_means = [i for i in range(10)]\n",
    "\n",
    "run_nearest_neighbors(X_means, y_means, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd15951e",
   "metadata": {},
   "source": [
    "As seen above, accuracy actually decreased a bit using class means.\n",
    "\n",
    "Let's try another model, what about decision trees?\n",
    "Here I ran a Decision Tree model using different max depths "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "be34d989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max depth 1 the accuracy is 0.1993\n",
      "For max depth 2 the accuracy is 0.3475\n",
      "For max depth 3 the accuracy is 0.5360\n",
      "For max depth 4 the accuracy is 0.7080\n",
      "For max depth 5 the accuracy is 0.7248\n",
      "For max depth 6 the accuracy is 0.7460\n",
      "For max depth 7 the accuracy is 0.7538\n",
      "For max depth 8 the accuracy is 0.7538\n",
      "For max depth 9 the accuracy is 0.7538\n",
      "For max depth 10 the accuracy is 0.7538\n",
      "For max depth 11 the accuracy is 0.7538\n",
      "For max depth 12 the accuracy is 0.7538\n",
      "For max depth 13 the accuracy is 0.7538\n",
      "For max depth 14 the accuracy is 0.7538\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(1,15) :\n",
    "    tree = DecisionTreeClassifier(max_depth=i, random_state=11)\n",
    "    tree.fit(X, y)\n",
    "    print(f'For max depth {i} the accuracy is {tree.score(X,y):.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0a6451",
   "metadata": {},
   "source": [
    "As seen above, accuracy using a decision tree improved a bit to 75%. This makes me happy, because the dataset authors stated that \n",
    ">It's valuable to know the optimal Bayes rate for these databases. In this case, the misclassification rate is 26% (74% classification accuracy).\n",
    "\n",
    "Which makes the accuracy I got here a little higher.\n",
    "Also, it seems like the accuracy plateaued at a max depth of 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e52e40",
   "metadata": {},
   "source": [
    "Let's also try the Bayes model, since it was mentioned by the authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "13c5785a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is 0.7133333333333334\n"
     ]
    }
   ],
   "source": [
    "gnb = GaussianNB()\n",
    "y_pred = gnb.fit(X_train, y_train).predict(X_test)\n",
    "acc = np.sum(y_pred == y_test)/len(y_test)\n",
    "print(f'The accuracy is {acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2dfd96",
   "metadata": {},
   "source": [
    "There isn't much improvement compared to knn, and it's lower than the decision tree."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0b3cba",
   "metadata": {},
   "source": [
    "In conclusion, the results show that for this dataset, a decision tree model of depth 7 was the best at predicting future values with an accuracy of 75%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987152d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
